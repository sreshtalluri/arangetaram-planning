---
phase: 04-ai-enhancement
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - frontend/package.json
  - frontend/src/lib/ai-client.ts
  - frontend/src/hooks/useChat.ts
  - frontend/src/hooks/useRecommendations.ts
autonomous: true

must_haves:
  truths:
    - "useChat hook streams responses word-by-word from ai-chat endpoint"
    - "useRecommendations hook fetches AI-ranked vendors grouped by category"
    - "Both hooks handle loading, error, and retry states"
  artifacts:
    - path: "frontend/src/lib/ai-client.ts"
      provides: "SSE fetch helpers for Edge Functions"
      exports: ["fetchSSE", "AI_ENDPOINTS"]
    - path: "frontend/src/hooks/useChat.ts"
      provides: "Chat state management with streaming"
      exports: ["useChat"]
    - path: "frontend/src/hooks/useRecommendations.ts"
      provides: "Recommendation fetching with React Query"
      exports: ["useRecommendations"]
  key_links:
    - from: "frontend/src/hooks/useChat.ts"
      to: "ai-chat Edge Function"
      via: "fetchSSE to /functions/v1/ai-chat"
      pattern: "ai-chat"
    - from: "frontend/src/hooks/useRecommendations.ts"
      to: "ai-recommendations Edge Function"
      via: "fetch to /functions/v1/ai-recommendations"
      pattern: "ai-recommendations"
---

<objective>
Create frontend hooks for consuming AI Edge Functions - streaming chat and recommendation fetching.

Purpose: React hooks that components will use to interact with AI features. useChat handles SSE streaming; useRecommendations uses React Query for caching.
Output: Installable eventsource-parser, ai-client.ts with SSE helpers, useChat.ts with streaming state, useRecommendations.ts with React Query.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/04-ai-enhancement/04-CONTEXT.md
@.planning/phases/04-ai-enhancement/04-RESEARCH.md
@.planning/phases/04-ai-enhancement/04-01-SUMMARY.md
@frontend/package.json
@frontend/src/lib/supabase.ts
@frontend/src/hooks/useEvents.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install eventsource-parser and create AI client library</name>
  <files>
    frontend/package.json
    frontend/src/lib/ai-client.ts
  </files>
  <action>
  Install eventsource-parser for SSE parsing:
  ```bash
  cd frontend && yarn add eventsource-parser
  ```

  Create **frontend/src/lib/ai-client.ts:**

  ```typescript
  import { createParser, type EventSourceParser } from 'eventsource-parser'
  import { supabase } from './supabase'

  // Edge Function endpoints
  export const AI_ENDPOINTS = {
    chat: `${process.env.REACT_APP_SUPABASE_URL}/functions/v1/ai-chat`,
    recommendations: `${process.env.REACT_APP_SUPABASE_URL}/functions/v1/ai-recommendations`,
  }

  /**
   * Fetch with SSE streaming support
   * @param url - Edge Function URL
   * @param body - Request body
   * @param onChunk - Callback for each text chunk
   * @param signal - AbortSignal for cancellation
   */
  export async function fetchSSE(
    url: string,
    body: Record<string, unknown>,
    onChunk: (text: string) => void,
    signal?: AbortSignal
  ): Promise<void> {
    const { data: { session } } = await supabase.auth.getSession()

    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${session?.access_token || ''}`,
      },
      body: JSON.stringify(body),
      signal,
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'Request failed' }))
      throw new Error(error.error || `HTTP ${response.status}`)
    }

    const reader = response.body?.getReader()
    if (!reader) throw new Error('No response body')

    const decoder = new TextDecoder()

    const parser = createParser({
      onEvent: (event) => {
        if (event.data === '[DONE]') return
        try {
          const { text } = JSON.parse(event.data)
          if (text) onChunk(text)
        } catch {
          // Ignore parse errors for malformed chunks
        }
      },
    })

    while (true) {
      const { done, value } = await reader.read()
      if (done) break
      parser.feed(decoder.decode(value, { stream: true }))
    }
  }

  /**
   * Fetch recommendations (non-streaming)
   */
  export async function fetchRecommendations(eventId: string) {
    const { data: { session } } = await supabase.auth.getSession()

    const response = await fetch(AI_ENDPOINTS.recommendations, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${session?.access_token || ''}`,
      },
      body: JSON.stringify({ eventId }),
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'Request failed' }))
      throw new Error(error.error || `HTTP ${response.status}`)
    }

    return response.json()
  }
  ```
  </action>
  <verify>
  ```bash
  cd /Users/sreshtalluri/Documents/Github/arangetaram-planning/frontend && cat package.json | grep eventsource-parser
  cat src/lib/ai-client.ts | grep -E "(fetchSSE|fetchRecommendations|AI_ENDPOINTS)"
  ```
  </verify>
  <done>eventsource-parser installed and ai-client.ts exports fetchSSE, fetchRecommendations, AI_ENDPOINTS</done>
</task>

<task type="auto">
  <name>Task 2: Create useChat hook with streaming support</name>
  <files>frontend/src/hooks/useChat.ts</files>
  <action>
  Create **frontend/src/hooks/useChat.ts:**

  ```typescript
  import { useState, useCallback, useRef } from 'react'
  import { fetchSSE, AI_ENDPOINTS } from '../lib/ai-client'
  import type { Event } from './useEvents'

  export interface ChatMessage {
    role: 'user' | 'assistant'
    content: string
  }

  interface UseChatOptions {
    eventContext?: Event | null
  }

  interface UseChatReturn {
    messages: ChatMessage[]
    isStreaming: boolean
    error: string | null
    sendMessage: (content: string) => Promise<void>
    clearMessages: () => void
  }

  const WELCOME_MESSAGE: ChatMessage = {
    role: 'assistant',
    content: 'Namaste! I can help you plan your Arangetram. Ask me about budgets, timelines, vendor categories, or anything else about your special day.',
  }

  export function useChat({ eventContext }: UseChatOptions = {}): UseChatReturn {
    const [messages, setMessages] = useState<ChatMessage[]>([WELCOME_MESSAGE])
    const [isStreaming, setIsStreaming] = useState(false)
    const [error, setError] = useState<string | null>(null)
    const abortControllerRef = useRef<AbortController | null>(null)

    const sendMessage = useCallback(async (content: string) => {
      if (!content.trim() || isStreaming) return

      // Cancel any pending request
      abortControllerRef.current?.abort()
      abortControllerRef.current = new AbortController()

      setError(null)
      setIsStreaming(true)

      // Add user message
      const userMessage: ChatMessage = { role: 'user', content: content.trim() }
      setMessages(prev => [...prev, userMessage])

      // Add placeholder for assistant response
      const assistantPlaceholder: ChatMessage = { role: 'assistant', content: '' }
      setMessages(prev => [...prev, assistantPlaceholder])

      try {
        await fetchSSE(
          AI_ENDPOINTS.chat,
          {
            message: content.trim(),
            eventContext: eventContext || undefined,
            history: messages.slice(-10), // Last 10 messages for context
          },
          (text) => {
            // Append streamed text to last message
            setMessages(prev => {
              const updated = [...prev]
              const lastIdx = updated.length - 1
              updated[lastIdx] = {
                ...updated[lastIdx],
                content: updated[lastIdx].content + text,
              }
              return updated
            })
          },
          abortControllerRef.current.signal
        )
      } catch (err) {
        if ((err as Error).name === 'AbortError') return

        setError((err as Error).message || 'Failed to get response')
        // Update placeholder with error message
        setMessages(prev => {
          const updated = [...prev]
          const lastIdx = updated.length - 1
          updated[lastIdx] = {
            ...updated[lastIdx],
            content: 'I apologize, but I encountered an issue. Please try again.',
          }
          return updated
        })
      } finally {
        setIsStreaming(false)
      }
    }, [messages, isStreaming, eventContext])

    const clearMessages = useCallback(() => {
      abortControllerRef.current?.abort()
      setMessages([WELCOME_MESSAGE])
      setError(null)
    }, [])

    return { messages, isStreaming, error, sendMessage, clearMessages }
  }
  ```
  </action>
  <verify>
  ```bash
  cat /Users/sreshtalluri/Documents/Github/arangetaram-planning/frontend/src/hooks/useChat.ts | grep -E "(export function useChat|sendMessage|isStreaming|fetchSSE)"
  ```
  </verify>
  <done>useChat hook exports with streaming support, message state, and error handling</done>
</task>

<task type="auto">
  <name>Task 3: Create useRecommendations hook with React Query</name>
  <files>frontend/src/hooks/useRecommendations.ts</files>
  <action>
  Create **frontend/src/hooks/useRecommendations.ts:**

  ```typescript
  import { useQuery, useQueryClient } from '@tanstack/react-query'
  import { fetchRecommendations } from '../lib/ai-client'
  import type { PublicVendor } from './useVendors'

  export interface RecommendedVendor extends PublicVendor {
    aiExplanation: string
  }

  export interface CategoryRecommendations {
    vendors: RecommendedVendor[]
  }

  export interface RecommendationsResponse {
    categories: Record<string, CategoryRecommendations>
  }

  interface UseRecommendationsOptions {
    eventId: string | undefined
    enabled?: boolean
  }

  /**
   * Fetch AI-powered vendor recommendations for an event
   * Uses hybrid approach: database filter then AI ranking
   */
  export function useRecommendations({ eventId, enabled = true }: UseRecommendationsOptions) {
    const queryClient = useQueryClient()

    const query = useQuery({
      queryKey: ['recommendations', eventId],
      queryFn: async (): Promise<RecommendationsResponse> => {
        if (!eventId) throw new Error('Event ID required')
        return fetchRecommendations(eventId)
      },
      enabled: !!eventId && enabled,
      staleTime: 5 * 60 * 1000, // Cache for 5 minutes
      retry: 1, // Auto-retry once on failure (per CONTEXT.md)
    })

    // Refresh recommendations (invalidate cache)
    const refreshRecommendations = () => {
      if (eventId) {
        queryClient.invalidateQueries({ queryKey: ['recommendations', eventId] })
      }
    }

    return {
      ...query,
      recommendations: query.data?.categories || {},
      refreshRecommendations,
    }
  }

  /**
   * Get recommendations for a specific category
   */
  export function useCategoryRecommendations(eventId: string | undefined, category: string) {
    const { recommendations, ...rest } = useRecommendations({ eventId })
    return {
      ...rest,
      vendors: recommendations[category]?.vendors || [],
    }
  }
  ```
  </action>
  <verify>
  ```bash
  cat /Users/sreshtalluri/Documents/Github/arangetaram-planning/frontend/src/hooks/useRecommendations.ts | grep -E "(export function|useQuery|refreshRecommendations)"
  ```
  </verify>
  <done>useRecommendations hook exports with React Query caching, refresh capability, and category helper</done>
</task>

</tasks>

<verification>
- [ ] eventsource-parser in frontend/package.json dependencies
- [ ] frontend/src/lib/ai-client.ts exports fetchSSE, fetchRecommendations, AI_ENDPOINTS
- [ ] frontend/src/hooks/useChat.ts exports useChat with streaming state
- [ ] frontend/src/hooks/useRecommendations.ts exports useRecommendations with React Query
- [ ] useChat handles abort/cancellation for rapid messages
- [ ] useRecommendations has refreshRecommendations function
- [ ] Both hooks import from ai-client.ts
</verification>

<success_criteria>
Frontend hooks ready for component integration:
- useChat provides { messages, sendMessage, isStreaming, error, clearMessages }
- useRecommendations provides { recommendations, isLoading, error, refreshRecommendations }
- TypeScript compiles without errors: `cd frontend && yarn type-check`
</success_criteria>

<output>
After completion, create `.planning/phases/04-ai-enhancement/04-02-SUMMARY.md`
</output>
